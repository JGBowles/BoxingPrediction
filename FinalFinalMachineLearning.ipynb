{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing/data clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387427, 26)\n",
      "win_A    321661\n",
      "win_B     40994\n",
      "draw      24772\n",
      "Name: result, dtype: int64\n",
      "drawless shape\n",
      "(362655, 26)\n",
      "win_A    2500\n",
      "win_B    2500\n",
      "Name: result, dtype: int64\n",
      "(5000, 26)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "df = pd.read_csv(\"bouts_out_new.csv\")\n",
    "\n",
    "# INITIAL INSPECTION\n",
    "\n",
    "# This is the shape of the data\n",
    "print(df.shape)\n",
    "print(df['result'].value_counts())\n",
    "\n",
    "# Remove draws\n",
    "df = df[df.result != 'draw']\n",
    "print(\"drawless shape\")\n",
    "print(df.shape)\n",
    "\n",
    "# Random under sample\n",
    "winAcount, winBcount = df.result.value_counts()\n",
    "df_winA = df[df['result'] == \"win_A\"]\n",
    "df_winB = df[df['result'] == \"win_B\"]\n",
    "df_winA_reduced = df_winA.sample(winBcount)\n",
    "\n",
    "df_winB_reduced = df_winB\n",
    "df_winA_reduced = df_winA.sample(2500)\n",
    "df_winB_reduced = df_winB.sample(2500)\n",
    "\n",
    "df = pd.concat([df_winA_reduced, df_winB_reduced], axis=0)\n",
    "print(df.result.value_counts())\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# These are the features I am working with\n",
    "#print(df.columns)\n",
    "\n",
    "# Shows that reach_b is missing 349K times, a lot of the score cards are \n",
    "# missing aswell as the physical features \n",
    "#print(df.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "# The data shows that fighter A is recorded as winning the most \n",
    "\n",
    "\n",
    "# If I create a new dataframe with purely complete records I only get 2800 records\n",
    "# removed_df = df.dropna(how='any')\n",
    "# print(\"Inconsistent records removed shape\")\n",
    "# print(removed_df.shape)\n",
    "\n",
    "# There's 3 unique values for a result meaning it is multiclass classification\n",
    "#print(df['result'].value_counts()) \n",
    "\n",
    "# PRE-PROCESSING AND CLEAN-UP\n",
    "\n",
    "# Encode the label \n",
    "le = preprocessing.LabelEncoder().fit(df['result'])\n",
    "encoded = le.transform(df['result'])\n",
    "df['result'] = encoded\n",
    "target = df['result']\n",
    "clean_df = df.drop(['result'], axis=1)\n",
    "\n",
    "\n",
    "#print(clean_df.head)\n",
    "\n",
    "# Models can only handle numeric features so I convert the non-numeric features\n",
    "# into numeric using dummy features\n",
    "clean_df = pd.get_dummies(clean_df)\n",
    "\n",
    "# This results in more features \n",
    "#print(\"Clean dataframe columns\")\n",
    "#print(clean_df.columns)\n",
    "#print(clean_df.shape)\n",
    "\n",
    "# Convert result to numeric data \n",
    "#result_conversion = {'win_A': 0, 'win_B': 1, 'draw': 2}\n",
    "#target = target.replace({'result': result_conversion}).infer_objects()\n",
    "#print(type(target['result']))\n",
    "\n",
    "#target = clean_df[['result_win_A', 'result_win_B', 'result_draw']]\n",
    "#print(\"Target dummied\")\n",
    "#print(target.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "# Imputes the mean for missing values - link to paper\n",
    "the_imputer = Imputer(missing_values= 'NaN', strategy='mean', axis=0)\n",
    "the_imputer.fit(clean_df)\n",
    "clean_df = pd.DataFrame(data=the_imputer.transform(clean_df), columns=clean_df.columns)\n",
    "\n",
    "\n",
    "#clean_df = clean_df[clean_df.result != ]\n",
    "\n",
    "# All records now have no missing features \n",
    "#print(clean_df.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "# Test both imputed values aswell as a completely clean dataset\n",
    "\n",
    "# SCALING \n",
    "# Use MinMaxScaler to scale all values\n",
    "# USe for KNN algorithm \n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaled_df = scaler.fit_transform(clean_df)\n",
    "clean_df = pd.DataFrame(scaled_df, columns=clean_df.columns)\n",
    "#print(\"Type of scaled df \" + str(type(clean_df)))\n",
    "#print(\"Shape of scaled df \" + str(clean_df.shape))\n",
    "\n",
    "\n",
    "# Split the dataset, splits the dataset 75%/25%, shuffles the dataset (see the book)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     clean_df, \n",
    "     target, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "#print(y_test.shape)\n",
    "#print(X_train.head)\n",
    "\n",
    "# Split the reduced 2800 dataset, splits the dataset 75%/25%, shuffles the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    clean_df, \n",
    "    target, random_state=0)\n",
    "\n",
    "\n",
    "# Select the 20 best features to reduce dimensionality \n",
    "import sklearn.feature_selection\n",
    "\n",
    "selection = sklearn.feature_selection.SelectKBest(chi2, k=20)\n",
    "selected_features = selection.fit(clean_df, target) # on x_train and y_train but save cleandf_2 as usual \n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [clean_df.columns[i] for i in indices_selected]\n",
    "\n",
    "clean_df2 = clean_df[colnames_selected]\n",
    "\n",
    "selection = sklearn.feature_selection.SelectKBest(chi2, k=20)\n",
    "selected_features = selection.fit(X_train, y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [clean_df.columns[i] for i in indices_selected]\n",
    "\n",
    "X = clean_df[colnames_selected]\n",
    "\n",
    "#print(clean_df2.shape)\n",
    "\n",
    "# print(X_train_selected.columns)\n",
    "# print(X_train_selected.head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6497034306195596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# for i in range(1, 11):\n",
    "knn = knn = KNeighborsClassifier(n_neighbors=5)\n",
    "#     knn.fit(X_train_selected, y_train)\n",
    "#     print(\"Normal:\" + str(knn.score(X_test_selected, y_test)))\n",
    "\n",
    "scores = cross_val_score(knn, X_test_selected, y_test, cv=10)\n",
    "print(scores.mean())\n",
    "    \n",
    "# knn = knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(X_train_selected, y_train)\n",
    "# print(\"Actual reduced:\" + str(knn.score(X_test_selected, y_test)))\n",
    "\n",
    "#scores = cross_val_score(knn, X_test_selected, y_test, cv=10)\n",
    "#print(scores.mean())\n",
    "\n",
    "# knn = knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(clean_df2, target)\n",
    "# print(\"Assumed reduced:\" + str(knn.score(clean_df2, target)))\n",
    "\n",
    "\n",
    "# for i in range(1, 11):\n",
    "#     knn = KNeighborsClassifier(n_neighbors=i)\n",
    "#     scores = cross_val_score(knn, clean_df, target, cv=10)\n",
    "#     print(\"Number of neighbors: \" + str(i) + \"\\nDataset with 36 features scores: {}\".format(scores))\n",
    "#     print(\"Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "#     # SelectKBest Results applied\n",
    "#     scores = cross_val_score(knn, clean_df2, target, cv=10)\n",
    "#     print(\"Number of neighbors: \" + str(i) + \"\\nDataset with 20 features scores: {}\".format(scores))\n",
    "#     print(\"Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "\n",
    "# Benefit of using cross-validation:\n",
    "# -\tTrain test split performs a random split, we could get lucky with the data split. \n",
    "# -\tWith cross validation each example will be in the training set exactly once. \n",
    "# -\tWe get a best case and a worst case scenario with the multiple folds as opposed to the one accuracy. \n",
    "# Another benefit of cross-validation as compared to using a single split of the data is\n",
    "# that we use our data more effectively. When using train_test_split, we usually use\n",
    "# 75% of the data for training and 25% of the data for evaluation. When using five-fold\n",
    "# cross-validation, in each iteration we can use four-fifths of the data (80%) to fit the\n",
    "# model. When using 10-fold cross-validation, we can use nine-tenths of the data\n",
    "# (90%) to fit the model. More data will usually result in more accurate models.\n",
    "\n",
    "# As the simple k-fold strategy fails here, scikit-learn does not use it for classification,\n",
    "# but rather uses stratified k-fold cross-validation. In stratified cross-validation, we\n",
    "# split the data such that the proportions between classes are the same in each fold as\n",
    "# they are in the whole dataset, as illustrated in Figure 5-2:\n",
    "# For example, if 90% of your samples belong to class A and 10% of your samples\n",
    "# belong to class B, then stratified cross-validation ensures that in each fold, 90% of\n",
    "# samples belong to class A and 10% of samples belong to class B.\n",
    "\n",
    "# Talk about benefits of cross validation etc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#       clean_df, \n",
    "#       target, random_state=0)\n",
    "\n",
    "# logreg = LogisticRegression().fit(X_train, y_train)\n",
    "# print(logreg.score(X_train, y_train))\n",
    "# print(logreg.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# High training set accuracy/low test set accuracy means overfitting \n",
    "# When both train/test is similar, means underfitting \n",
    "\n",
    "# C = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# for i in C:\n",
    "#     logreg = LogisticRegression(C=i)\n",
    "#     scores = cross_val_score(logreg, clean_df, target, cv=10)\n",
    "#     print(\"Full features: When C = \" + str(i) + \". Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "#     scores = cross_val_score(logreg, clean_df2, target, cv=10)\n",
    "#     print(\"Reduced features: When C = \" + str(i) + \". Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# for i in range(1, 100):\n",
    "#     logreg = LogisticRegression(C=i)\n",
    "#     scores = cross_val_score(logreg, clean_df, target, cv=10)\n",
    "#     print(\"Full features: When C = \" + str(i) + \". Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "#     scores = cross_val_score(logreg, clean_df2, target, cv=10)\n",
    "#     print(\"Reduced features: When C = \" + str(i) + \". Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "    \n",
    "# for i in range(1, 101):\n",
    "#     logreg = LogisticRegression(C=i).fit(X_train, y_train)\n",
    "#     print(\"When C is equal to \" + str(i) + \" training set result : \" + str(logreg.score(X_train, y_train)))\n",
    "#     print(\"When C is equal to \" + str(i) + \" test set result : \" + str(logreg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# logreg = LogisticRegression(C=100)#.fit(X_train, y_train)\n",
    "\n",
    "# scores = cross_val_score(logreg, clean_df, target, cv=10)\n",
    "# print(\"Dataset with 36 features scores: {}\".format(scores))\n",
    "# print(\"Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# scores = cross_val_score(logreg, clean_df2, target, cv=10)\n",
    "# print(\"Dataset with 20 features scores: {}\".format(scores))\n",
    "# print(\"Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# If we're overfitting \n",
    "# When the test and training set score are close it means I am likely underfitting\n",
    "# print(\"Training set score \" + str(logreg.score(X_train, y_train)))\n",
    "#print(\"Test set score \" + str(logreg.score(X_test, y_test)))\n",
    "# You will need to explain alpha and regularization in this section, not the lit review\n",
    "\n",
    "# C is changed, this relates to regularization I think, talk about this, this means\n",
    "# less regularization\n",
    "# logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "# print(\"Training set score: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "# print(\"Test set score: {:.3f}\".format(logreg100.score(X_test, y_test)))\n",
    "\n",
    "# C is set to 0.01, this means even more regularization\n",
    "# logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "# print(\"Training set score: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "# print(\"Test set score: {:.3f}\".format(logreg001.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # As mentioned in the literature review, a Random Forest comprises of decision\n",
    "# trees. When a decision tree is built that continues until all leaves are pure leads to models\n",
    "# that are very complex and highly overfit to the training data. The presence of pure\n",
    "# leaves means that a tree is 100% accurate on the training set. \n",
    "# To stop the overfitting of trees we can pre-prune the tree or post-prune the tree\n",
    "# To pre-prune we can limit the maximum depth of the tree \n",
    "# The deeper a tree becomes the more complex it becomes. Limiting the depth\n",
    "# prevents overfitting\n",
    "# try a standard decision tree aswell as this one \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# n estimators equal the number of trees\n",
    "# Iterate thropugh a number of numbers of trees to gauge the best\n",
    "# A heavy tuning of parameters is not really needed\n",
    "# max depth is set to default\n",
    "\n",
    "    \n",
    "\n",
    "# forest = RandomForestClassifier(n_estimators=460, n_jobs=-1, max_features = 'sqrt', max_depth= 28)\n",
    "\n",
    "# scores = cross_val_score(forest, clean_df, target, cv=10)\n",
    "# print(\"Full features: mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# scores = cross_val_score(forest, clean_df2, target, cv=10)\n",
    "# print(\"Reduced features: Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# omit samples/leafs and just reflect on it\n",
    "\n",
    "# forest = RandomForestClassifier()\n",
    "\n",
    "# scores = cross_val_score(forest, clean_df, target, cv=10)\n",
    "# print(\"Full features: mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# scores = cross_val_score(forest, clean_df2, target, cv=10)\n",
    "# print(\"Reduced features: Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# forest.fit(X_train, y_train)\n",
    "# print(forest.score(X_test, y_test))\n",
    "\n",
    "#Random Grid Search\n",
    "# n_estimators = [int(x) for x in np.linspace(start=200, stop=500, num=10)]\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# max_depth = [int(x) for x in np.linspace(5, 100, num = 5)]\n",
    "# max_depth.append(None)\n",
    "\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth\n",
    "#               }\n",
    "\n",
    "# forest = RandomForestClassifier()\n",
    "\n",
    "# rf_random = RandomizedSearchCV(estimator = forest, param_distributions = random_grid, n_iter = 100, cv = 3, n_jobs=-1, verbose=3, random_state=42)\n",
    "# rf_random.fit(X_train, y_train)\n",
    "# print(rf_random.best_params_)\n",
    "\n",
    "# Grid search CV \n",
    "\n",
    "# param_grid = {\n",
    "#     'max_depth' : [20, 25, 28, 30, 35],\n",
    "#     'max_features': ['sqrt'],\n",
    "#     'n_estimators' : [450, 460, 466, 470, 475]\n",
    "# }\n",
    "\n",
    "# forest = RandomForestClassifier()\n",
    "\n",
    "# grid_search = GridSearchCV(estimator = forest, param_grid = param_grid, cv = 3, n_jobs=-1, verbose=3)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "#grid_search.fit(X_train, y_train)\n",
    "#print(grid_search.best_params_)\n",
    "\n",
    "#print(str(forest.score(X_test, y_test)))\n",
    "\n",
    "# Also use AUC from April chen's video\n",
    "# Assess with cross validation\n",
    "# Test on both the 20 features aswell as all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# Need to debug this, it returns 100% accuracy??? - fixed \n",
    "gnb_clf = MultinomialNB()\n",
    "\n",
    "scores = cross_val_score(gnb_clf, clean_df, target, cv=10)\n",
    "print(\"Full features: mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "scores = cross_val_score(gnb_clf, clean_df2, target, cv=10)\n",
    "print(\"Reduced features: Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "# Also use AUC from April chen's video\n",
    "# Assess with cross validation\n",
    "# Test on both the 20 features aswell as all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 0.7048348538810557\n",
      "Testing Accuracy 0.7093721032346197\n"
     ]
    }
   ],
   "source": [
    "#https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy \" + str(mlp.score(X_train, y_train)))\n",
    "print(\"Testing Accuracy \" + str(mlp.score(X_test, y_test)))\n",
    "\n",
    "# A common way to adjust parameters in a neural network is to first create a network\n",
    "# that is large enough to overfit, making sure that the task can actually be learned by\n",
    "# the network. Then, once you know the training data can be learned, either shrink the\n",
    "# network or increase alpha to add regularization, which will improve generalization\n",
    "# performance.\n",
    "\n",
    "# Algorithms part - http://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "# # Poor accuracy could be down to poor scaling, scale with minmax scaler and see\n",
    "# # if there';s an improvement in accuracy \n",
    "# # Either use minmax scaler or scale from cristi vlad video, standardscaler\n",
    "# # neural networks 3 \n",
    "# # Decent accuracy \n",
    "# # By default the MLP uses 100 hidden nodes\n",
    "#print(\"Accuracy \" + str(mlp.score(X_test, y_test)))\n",
    "\n",
    "# Reduced the number of hidden nodes - 10 hidden units\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=[10], random_state=42)\n",
    "# mlp.fit(X_train, y_train)\n",
    "# print(\"Accuracy \" + str(mlp.score(X_test, y_test)))\n",
    "\n",
    "# Two hidden layers now with 10 nodes each\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=[10, 10], random_state=42)\n",
    "# mlp.fit(X_train, y_train)\n",
    "# print(\"Accuracy \" + str(mlp.score(X_test, y_test)))\n",
    "\n",
    "# Experiment with the alpha some more \n",
    "# mlp = MLPClassifier(hidden_layer_sizes=[10, 10], alpha=1, random_state=42)\n",
    "# mlp.fit(X_train, y_train)\n",
    "# print(\"Accuracy \" + str(mlp.score(X_test, y_test)))\n",
    "\n",
    "# Also use AUC from April chen's video\n",
    "# Assess with cross validation\n",
    "# Test on both the 20 features aswell as all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full features: mean of the scores: 0.75\n",
      "Reduced features: Mean of the scores: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear', gamma=33, C=100)\n",
    "\n",
    "scores = cross_val_score(svc, clean_df, target, cv=10, n_jobs=-1)\n",
    "print(\"Full features: mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "scores = cross_val_score(svc, clean_df2, target, cv=10)\n",
    "print(\"Reduced features: Mean of the scores: {:.2f}\".format(scores.mean()))\n",
    "\n",
    "\n",
    "#Random Grid Search\n",
    "# kernel = ['rbf', 'sigmoid', 'linear']\n",
    "# Cs = [x for x in np.linspace(start=0.001, stop=100, num=10)]\n",
    "# gammas = [x for x in np.linspace(start=0.001, stop=100, num=10)]\n",
    "# random_grid = {'kernel' : kernel, 'C' : Cs, 'gamma' : gammas}\n",
    "# svc = SVC()\n",
    "# svc_random = RandomizedSearchCV(estimator = svc, param_distributions = random_grid, n_iter = 100, cv = 3, n_jobs=-1, verbose=5, random_state=42)\n",
    "# svc_random.fit(X_train, y_train)\n",
    "# print(svc_random.best_params_)\n",
    "\n",
    "# test each kernel, take best, then perform search \n",
    "\n",
    "\n",
    "\n",
    "# Grid search CV \n",
    "\n",
    "# param_grid = {\n",
    "#     'max_depth' : [20, 25, 28, 30, 35],\n",
    "#     'max_features': ['sqrt'],\n",
    "#     'n_estimators' : [450, 460, 466, 470, 475]\n",
    "# }\n",
    "\n",
    "# forest = RandomForestClassifier()\n",
    "\n",
    "# grid_search = GridSearchCV(estimator = forest, param_grid = param_grid, cv = 3, n_jobs=-1, verbose=3)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "# grid_search = GridSearchCV(SVC(), param_grid, cv=3, n_jobs= -1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "\n",
    "# svc = SVC()\n",
    "# clf = \n",
    "# svc.fit(X_train, y_train)\n",
    "# print(\"Score \" + str(svc.score(X_test, y_test)))\n",
    "# Assess with cross validation\n",
    "# Test on both the 20 features aswell as all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 25 is out of bounds for axis 0 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7dad558f219d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mindices_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcolnames_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices_selected\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mX_train_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolnames_selected\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-7dad558f219d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mindices_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mcolnames_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices_selected\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mX_train_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolnames_selected\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 25 is out of bounds for axis 0 with size 25"
     ]
    }
   ],
   "source": [
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    # Import dataset, make seperate dataset for the target\n",
    "    df = pd.read_csv(\"bouts_out_new.csv\")\n",
    "    target = df['result']\n",
    "    clean_df = df.drop(['result'], axis=1)\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=460, n_jobs=-1, max_features = 'sqrt', max_depth= 28)\n",
    "\n",
    "    selection = sklearn.feature_selection.SelectKBest(chi2, k=20)\n",
    "    selected_features = selection.fit(X_train, y_train)\n",
    "    indices_selected = selected_features.get_support(indices=True)\n",
    "    colnames_selected = [clean_df.columns[i] for i in indices_selected]\n",
    "\n",
    "    X_train_selected = X_train[colnames_selected]\n",
    "    X_test_selected = X_test[colnames_selected]\n",
    "\n",
    "    scores = cross_val_score(forest, X_train_selected, X_test_selected, cv=10)\n",
    "    print(\"Reduced features: mean of the scores: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
